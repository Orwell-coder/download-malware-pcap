#!/usr/bin/env python3
# -*- coding:utf-8 -*-

################################################################
#
# @description: 下载stratosphereips.org恶意pcap文件
# @date: 2021/01/16 20:30
# @author: attempt321@163.com
# @version: 0.0.1
#
################################################################

import requests
from bs4 import BeautifulSoup
import re
import os
import pickle
from multiprocessing import Process
from contextlib import closing
import sys
import shutil
import zipfile
import argparse

class Malware(object):
    host = 'https://www.stratosphereips.org/datasets-malware#'
    __cache_path = './stratosphereips.org/cache'
    urls = []
    pcap_urls = []
    html = ''
    document = ''
    path = './stratosphereips.org/pcaps/'
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75'
    proxies = {}
    headers = {}
    # def __init__(self):
    #     pass

    def __cache(self, key, value='', minutes=60 * 24):
        """
        缓存
        @params key   缓存名
        @params value 缓存值
        @params minutes  缓存时间
        @return
        """
        if not os.path.isdir(self.__cache_path):
            os.mkdir(self.__cache_path)
        if os.path.isfile(key) and not value:
            with open(self.__cache_path + key, 'r') as f:
                f.read()
        with open(self.__cache_path, "wb") as f:
            f.write(bytearray(value))

    def get_html(self, url):

        self.html = requests.get(url,headers=self.headers, proxies=self.proxies)
        self.document = BeautifulSoup(self.html.content, 'html.parser')

        return self

    def match_urls(self):
        print('正在获取一级urls')
        div_tag = self.document.find('div', attrs={'class': 'sqs-block-content'})
        a_tags = div_tag.find_all('a')
        for a in a_tags:
            self.urls.append(a.get('href'))
        del self.urls[0]
        print('完成获取一级urls')
        return self

    def match_pcap_urls(self):
        print('正在获取二级urls')
        self.headers = {
            'User-Agent': self.user_agent,
            'Host': 'mcfp.felk.cvut.cz',
            'Referer': 'https://www.stratosphereips.org/'
        }
        for url in self.urls:
            try:
                self.get_html(url)
                table_tag = self.document.find('table')
                a_tags = table_tag.find_all('a')
                self.match_pcap_url(url, a_tags)
            except Exception as e:
                print('Exception: %s %s' % (url, e))
                continue

        print('完成获取二级urls')
        return self

    def match_pcap_url(self, prev_url, tags):
        # pattern = r'<a.+?href=\"(20.+?)\".*>'
        for a_tag in tags:
            try:
                href = a_tag.get('href')
                if '.pcap' in href:
                    self.pcap_urls.append(prev_url + href)
                    # print(href)
            except Exception as e:
                print('Exception : %s %s' % (a_tag, e))
                continue


    def save_url(self, urls=None):
        try:
            if not urls:
                urls = self.pcap_urls
            url_content = ''
            for url in urls:
                url_content += url + '\n'
            with open('stratosphereips.org/urls.txt', 'w+', encoding="utf-8") as f:
                f.write(url_content)
            print('保存url到文件中成功')
        except IOError as e:
            pass

    def download_pcap(self, urls=None):
        """
        @description 根据url下载pcap文件
        @param urls: list
        @return:
        """
        try:
            if not urls:
                urls = self.pcap_urls
            if not os.path.isdir(self.path):
                os.mkdir(self.path)
            headers = {
                'User-Agent':self.user_agent,
                'Host': 'mcfp.felk.cvut.cz',
                'Referer': 'https://www.stratosphereips.org/'
            }

            for url in urls:
                try:
                    file_name = url.split('/').pop()
                    print('\n开始下载：'+ file_name)

                    with closing(requests.get(url, headers=headers, proxies=self.proxies, stream=True)) as response:
                        chunk_size = 1024  # 单次请求最大值
                        content_size = int(response.headers['content-length'])
                        data_count = 0
                        file_path = self.path + file_name
                        # 文件存在, 跳过下载
                        if os.path.isfile(file_path) and os.path.getsize(file_path) >= content_size:
                            print('文件已存在！')
                            continue

                        with open(file_path, "wb") as file:
                            for data in response.iter_content(chunk_size=chunk_size):
                                file.write(data)
                                data_count = data_count + len(data)
                                progressing = (data_count / content_size) * 100
                                print("\r  文件下载进度：%d%%(%d/%d) - %s" % (progressing, data_count, content_size, file_name), end=" ")
                except KeyError as e:
                    print('KeyError: ', e)
                    continue
        except Exception as e:
            print('error ', e )

    def move(self, source, destination, depth:int = 1, filters = None):
        """
        @description 根据条件移动文件到指定目录
        @param source: 目录
        @param destination: 目的目录
        @param filters: 字典过滤条件
        @return:
        """
        if not os.path.isdir(source):
            raise ValueError('Directory is not exists of %s' % source)
        if not os.path.isdir(destination):
            os.mkdir(destination)

        files = []
        for file in os.listdir(source):
            try:
                if os.path.isfile(source + '/' + file):
                    if filters:
                        for (k, v) in filters.items():
                            if k == 'size' and os.path.getsize(source + '/' + file) > v:
                                files.append(file)
                            if k == 'ext' and os.path.splitext(file)[1] == v:
                                files.append(file)
                            if k == 'index' and file.index(v):
                                files.append(file)
                    else:
                        files.append(file)
            except Exception as e:
                print('Error: ', e)
                continue
        # cpoy 到指定目录
        [shutil.copyfile(source + '/' + file, destination + '/' + file) for file in files]

    def zip_extract(self, source, destination, passwd=None):
        """
        解压
        @param source:
        @param destination:
        @param passwd:
        @return:
        """
        if not os.path.isdir(source):
            raise ValueError('Directory is not exists of %s' % source)
        if not os.path.isdir(destination):
            os.mkdir(destination)

        files = [ file for file in os.listdir(source) if zipfile.is_zipfile(source + '/' + file)]

        for file in files:
            try:
                print('解压文件：', file)
                zip_file = zipfile.ZipFile(source + '/' + file)
                # zip_file = zip_file.namelist()
                # 转换为bytes字节编码
                zip_file.extractall(destination, pwd=passwd.encode('ascii'))
                zip_file.close()
            except Exception as e:
                print('Error: ' , e)
                continue




if __name__ == '__main__':
    # args = argparse.ArgumentParser()
    # args.add_argument('run')
    # subparsers = args.add_subparsers(help='sub-command help')
    # group = subparsers.add_parser('extract', help='extract -h --help')
    # group.add_argument('source', help='zip file by source directory')
    # group.add_argument('destination', help='extract zip file to destination directory')
    # group.add_argument('--passwd', help='To special password by extract zip file')
    # group2 = subparsers.add_parser('extract2', help='extract2 -h --help')
    # group2.add_argument('source', help='zip file by source directory')
    # group2.add_argument('destination', help='extract zip file to destination directory')
    try:
        args = sys.argv

        args_num = len(args)
        link = 'https://www.stratosphereips.org/datasets-malware#'
        mal = Malware()
        mal.proxies = {
            'http':'127.0.0.1:10809',
            'https':'127.0.0.1:10809'
        }
        if args_num >1 and args[1] == 'save' :
            mal.get_html(link).match_urls().match_pcap_urls().save_url()
        elif args_num > 1 and args[1] == 'download':
            mal.get_html(link).match_urls().match_pcap_urls().download_pcap()
        elif args_num > 1 and args[1] == 'download_by_urls_file':
            urls = []
            with open('stratosphereips.org/urls.txt', 'r', encoding='utf-8') as f:
                for line in f.readlines():
                    urls.append(line.strip())
            mal.download_pcap(urls)
        elif args_num > 1  and args[1] == 'move':

            if args_num != 5:
                print('params input error, please input again')
            source_dir = args[2]
            dest_dir = args[3]
            cond = args[4].strip('{}').split(',')
            filters = {}
            for filter in cond:
                (k, v) = filter.split('=')
                filters[k] = v
            mal.move(source_dir, dest_dir, filters=filters)
        elif args_num > 1 and args[1] == 'extract':
            if args_num != 5:
                print('params input error, please input again')
            source_dir = args[2]
            dest_dir = args[3]
            pwd = args[4]
            mal.zip_extract(source_dir, dest_dir, pwd)
        else:
            print('usage: ' + args[0] + ' optional')
            print(' save  获取pcap下载链接，并保存为urls.txt')
            print(' download   获取pcap下载链接，并直接下载文件')
            print(' download_by_urls_file  通过urls.txt下载文件')
            print(' move eg: move source destination "{k1=v1,k2=v2}"   : move files to directory by condition ')
            print(' extract  eg: extract source destination passwd : extract zip file by source directory to '
                  'destination directory')

    except Exception as e:
        print('Error: ', e)
